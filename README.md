
# Employee Data Analysis using Apache Spark

## Overview
This project aims to perform data analysis on employee data using Apache Spark in a Databricks workspace. The dataset, employee_data.csv, contains information such as ```Employee Number```, ``Employee Name``, ``Age``, ``Salary``, and ``Department``.

## Dataset Description
The dataset employee_data.csv comprises the following columns:

 - ``Emp_No``: Employee Number
 - ``Emp_Name``: Employee Name
 - ``Age``: Age of the Employee
 - ``Salary``: Salary of the Employee
 - ``Department``: Department to which the Employee belongs
## Setup
To get started with this analysis, follow these steps:

 - Clone the Repository.
 - Upload the Dataset.
 - Convert Dataset to Temporary Table.
## Findings
After setting up the environment and loading the data, we can perform various analyses on the employee dataset. Some potential findings include:

 - #### Average Age of Employees: 
   Calculate the average age of employees across all departments.

 - #### Average Salary by Department: 
   Find the average salary for each department.

 - #### Employee Count by Department: 
   Determine the number of employees in each department.

 - #### Highest Paid Employees: 
   Identify the employees with the highest salaries.

 - #### Age Distribution: 
   Analyze the distribution of employee ages.
## Running the Analysis
To run the analysis, execute the provided code file snippets ``Employee_Data_Analysis-PySpark-DBFS`` in a Databricks notebook. Make sure you have properly set up your Databricks environment and have access to the dataset.

## Contribution
Feel free to contribute to this project by submitting pull requests. Whether it's fixing a bug, adding a new feature, or improving documentation, all contributions are welcome!

If you liked this project, please consider starring it on GitHub. Your support is greatly appreciated!